# ğŸ“„ Pipeline documentaire â€“ Nettoyage â€¢ DÃ©doublonnage â€¢ Conversion â€¢ Classification â€¢ Export Markdown â€¢ Dataset LLM

## ğŸ§© SchÃ©ma global du pipeline

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚    raw/ (brut)     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ 1) clean_extension.py          â”‚
            â”‚ - Filtrage extensions          â”‚
            â”‚ - Suffixes antiâ€‘collision      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ clean_extension/                    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ 2) dedupe.py                   â”‚
            â”‚ - RÃ¨gles DOC/DOCX/PDF          â”‚
            â”‚ - SÃ©lection fichier le + rÃ©centâ”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚       dedupe/          â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3) convert_to_docx.py (parallÃ©lisÃ©)    â”‚
        â”‚ - DOC â†’ DOCX (LibreOffice)             â”‚
        â”‚ - PDF â†’ DOCX (pdf2docx)                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   docx/   â”‚
                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ 4) classify_docx.py                        â”‚
       â”‚ - Analyse 1Ã¨re page + nom fichier          â”‚
       â”‚ - DÃ©tection EDB / NDC / AUTRES             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ classified_docx/                              â”‚
         â”‚   â”œâ”€â”€ edb/   (CAGIPRITM...)                  â”‚
         â”‚   â”œâ”€â”€ ndc/   (CAGIPRITM...)                  â”‚
         â”‚   â””â”€â”€ autres/                                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 5) extract_docx_to_markdown.py (parallÃ©lisÃ©)       â”‚
      â”‚ - DOCX â†’ Markdown (Mammoth)                        â”‚
      â”‚ - Suppression TOC, page de garde                   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ markdown/                                 â”‚
         â”‚   â”œâ”€â”€ edb/*.md                           â”‚
         â”‚   â””â”€â”€ ndc/*.md                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 6) build_dataset_jsonl.py                          â”‚
      â”‚ - Appariement EDB â†” NDC par code RITM              â”‚
      â”‚ - Export JSONL pour fine-tuning                    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ train_dataset.jsonl                       â”‚
         â”‚ val_dataset.jsonl                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“˜ Description gÃ©nÃ©rale

Ce dÃ©pÃ´t contient un pipeline complet permettant de transformer un lot de documents bruts en un dataset prÃªt pour le fine-tuning LLM :

- Nettoyage et filtrage des fichiers
- DÃ©doublonnage intelligent
- Conversion homogÃ¨ne en DOCX
- Classification automatique (NDC / EDB / AUTRES)
- Export Markdown de qualitÃ©
- Constitution du dataset JSONL

Il repose sur **6 scripts Python**, exÃ©cutÃ©s dans cet ordre :

1. `clean_extension.py` â€” Filtrage des extensions valides
2. `dedupe.py` â€” DÃ©doublonnage intelligent
3. `convert_to_docx.py` â€” Conversion DOC/PDF â†’ DOCX (parallÃ©lisÃ©)
4. `classify_docx.py` â€” Classification EDB / NDC / AUTRES par code RITM
5. `extract_docx_to_markdown.py` â€” Export Markdown avec Mammoth (parallÃ©lisÃ©)
6. `build_dataset_jsonl.py` â€” Constitution dataset JSONL pour fine-tuning

**Code RITM** : Les fichiers sont identifiÃ©s par leur code `CAGIPRITMNNNNNNN` au dÃ©but du nom de fichier.

---

# ğŸš€ ExÃ©cution depuis un Pod JupyterLab (template *scribe*)

## âœ”ï¸ Instructions exactes

### **1) CrÃ©er un Pod**

- Template : **scribe**
- **Sans GPU**
- Ouvrir JupyterLab
- Ouvrir un Terminal

### **2) Installer l'environnement**

```bash
bash
git clone https://github.com/TeamCLP/datas.git /home/datas && source /home/datas/install.sh
```

Le script `install.sh` configure automatiquement :

- Proxy
- LibreOffice
- Miniconda + Python 3.13
- Environnement `pipeline`
- Installation du `requirements.txt`

### **3) DÃ©poser les donnÃ©es sources**

Placer `raw_datas.tar` dans `/home/datas` puis extraire :

```bash
tar -xvf raw_datas.tar -C raw/
```

### **4) Lancer le pipeline complet**

```bash
python clean_extension.py
python dedupe.py
python convert_to_docx.py
python classify_docx.py
python extract_docx_to_markdown.py
python build_dataset_jsonl.py --report
```

---

# ğŸ§± Architecture finale

```
datas/
â”œâ”€â”€ raw/                          # Fichiers bruts d'entrÃ©e
â”œâ”€â”€ clean_extension/              # Fichiers filtrÃ©s
â”œâ”€â”€ dedupe/                       # Fichiers dÃ©doublonnÃ©s
â”œâ”€â”€ docx/                         # Tous les fichiers en DOCX
â”œâ”€â”€ classified_docx/
â”‚   â”œâ”€â”€ edb/                      # Expressions de Besoin
â”‚   â”œâ”€â”€ ndc/                      # Notes de Cadrage
â”‚   â””â”€â”€ autres/                   # Non classÃ©s
â”œâ”€â”€ markdown/
â”‚   â”œâ”€â”€ edb/                      # EDB en Markdown
â”‚   â””â”€â”€ ndc/                      # NDC en Markdown
â”œâ”€â”€ train_dataset.jsonl           # Dataset d'entraÃ®nement
â”œâ”€â”€ val_dataset.jsonl             # Dataset de validation
â””â”€â”€ *.py                          # Scripts du pipeline
```

---

# âš™ï¸ 1. Nettoyage des extensions
**Script : `clean_extension.py`**

- Parcourt `raw/`
- Ne conserve que : `.pdf`, `.doc`, `.docx`
- Ajoute un suffixe `_YYYYMMDD_HHMMSS` en cas de collision
- Produit : `inventaire_raw.xlsx`

```bash
python clean_extension.py
```

---

# ğŸ§¹ 2. DÃ©doublonnage intelligent
**Script : `dedupe.py`**

| Cas | Conserver |
|-----|-----------|
| `.docx` prÃ©sent | `.docx` le plus rÃ©cent |
| `.doc` sans `.docx` | `.doc` le plus rÃ©cent |
| seulement PDF | PDF le plus rÃ©cent |

- Produit : `dedupe_report.xlsx`

```bash
python dedupe.py
```

---

# ğŸ” 3. Conversion DOC/PDF â†’ DOCX
**Script : `convert_to_docx.py`** (parallÃ©lisÃ©)

- Conversion `.doc` via LibreOffice
- Conversion `.pdf` via `pdf2docx`
- Copie des `.docx` existants
- Produit : `convert_report.xlsx`

```bash
python convert_to_docx.py
python convert_to_docx.py --workers 4  # limiter Ã  4 workers
```

---

# ğŸ” 4. Classification EDB / NDC / AUTRES
**Script : `classify_docx.py`**

Analyse de la **premiÃ¨re page** et du **nom de fichier** :

1. **NDC** si code client dÃ©tectÃ© en 1Ã¨re page
2. **EDB** si le nom contient "edb" ou "expression de besoin"
3. **NDC** si code client dÃ©tectÃ© dans le nom
4. **AUTRES** sinon

**Codes clients reconnus** : `CAPS`, `AVEM` (ex: `CAPS_2024_001`)

- Produit : `classify_report.xlsx`

```bash
python classify_docx.py
```

---

# ğŸ“¤ 5. Export Markdown
**Script : `extract_docx_to_markdown.py`** (parallÃ©lisÃ©)

- Scanne `classified_docx/edb/` et `classified_docx/ndc/`
- Identifie les fichiers par leur code RITM (`CAGIPRITMNNNNNNN`)
- Convertit les DOCX en Markdown via **Mammoth**
- Supprime automatiquement : page de garde, table des matiÃ¨res, prÃ©ambule
- Produit : `extract_report.xlsx`

```bash
python extract_docx_to_markdown.py
python extract_docx_to_markdown.py --workers 4
```

---

# ğŸ¤– 6. Constitution du dataset JSONL
**Script : `build_dataset_jsonl.py`**

- Scanne `markdown/edb/` et `markdown/ndc/`
- Apparie les fichiers EDB â†” NDC par code RITM commun
- GÃ¨re les cas multi-versions
- Split train/val (90/10 par dÃ©faut)
- Format Mistral Instruct
- Produit : `dataset_report.xlsx`

| StratÃ©gie | Description |
|-----------|-------------|
| `version_match` | Apparie par version (v1â†”v1) |
| `all_combinations` | Toutes les combinaisons EDBÃ—NDC |
| `latest_only` | Version la plus rÃ©cente uniquement |
| `first_only` | Premier fichier trouvÃ© |

```bash
python build_dataset_jsonl.py --report
python build_dataset_jsonl.py --strategy all_combinations --train_ratio 0.8
```

---

# ğŸ“Š Fichiers gÃ©nÃ©rÃ©s

| Ã‰tape | Fichier | Contenu |
|-------|---------|---------|
| 1 | `inventaire_raw.xlsx` | Inventaire et actions |
| 2 | `dedupe_report.xlsx` | DÃ©cisions de dÃ©doublonnage |
| 3 | `convert_report.xlsx` | Statut des conversions |
| 4 | `classify_report.xlsx` | Classification EDB/NDC/AUTRES |
| 5 | `extract_report.xlsx` | Extraction DOCX â†’ Markdown |
| 6 | `dataset_report.xlsx` | Appariements EDB/NDC et orphelins |
| 6 | `train_dataset.jsonl` | Dataset d'entraÃ®nement |
| 6 | `val_dataset.jsonl` | Dataset de validation |

---

# â­ Bonnes pratiques

- Toujours suivre le pipeline dans l'ordre
- Ne jamais modifier manuellement les dossiers intermÃ©diaires
- Utiliser `--report` pour diagnostiquer les problÃ¨mes
- VÃ©rifier les codes RITM communs entre EDB et NDC

---

# ğŸ§© RÃ©sultat attendu

Ã€ la fin du pipeline :

- Corpus nettoyÃ© et dÃ©doublonnÃ©
- Documents classÃ©s par type (EDB/NDC)
- Export Markdown de qualitÃ©
- Dataset JSONL prÃªt pour fine-tuning LLM
- TraÃ§abilitÃ© complÃ¨te via les rapports Excel
